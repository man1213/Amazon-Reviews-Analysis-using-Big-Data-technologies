{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon reviews LDA topic modeling - for EMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The notebook:\n",
    "- Train LDA model\n",
    "- Identify top topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9</td><td>application_1588267976982_0011</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-22-128.ec2.internal:20888/proxy/application_1588267976982_0011/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-31-107.ec2.internal:8042/node/containerlogs/container_1588267976982_0011_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fa4a94aaac8>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ML libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import CountVectorizer, IDF,RegexTokenizer, Tokenizer\n",
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import struct\n",
    "import re\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Retail data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "          .option(\"header\", \"true\")\\\n",
    "          .option(\"inferSchema\", \"true\")\\\n",
    "          .option(\"basePath\", \"hdfs:///hive/amazon-reviews-pds/parquet/\")\\\n",
    "          .parquet(\"hdfs:///hive/amazon-reviews-pds/parquet/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- product_category: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ml = df.filter((F.col(\"product_category\")==\"Digital_Ebook_Purchase\") | (F.col(\"product_category\")==\"Books\"))\n",
    "df_ml = df.filter((F.col(\"product_category\")==\"Digital_Ebook_Purchase\") \\\n",
    "                   & (F.col(\"year\")==2015) \\\n",
    "                   & (F.col(\"review_date\")<'2015-02-01')\n",
    "                   & (F.col(\"star_rating\")>3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new DF with only narrative and unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import monotonically_increasing_id, concat\n",
    "\n",
    "df1 = df_ml.withColumn('review_text', \n",
    "                       F.concat(F.col('review_headline'),F.lit(' '), F.col('review_body')))\n",
    "corpus =df1.select('review_text')\n",
    "\n",
    "# This will return a new DF with all the columns + id\n",
    "corpus_df = corpus.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "# Remove records with no review text\n",
    "corpus_df = corpus_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 466817\n",
      "+--------------------+----------+\n",
      "|         review_text|        id|\n",
      "+--------------------+----------+\n",
      "|Great story! Ray ...|8589934592|\n",
      "|Four Stars It's a...|8589934593|\n",
      "|Four Stars Good r...|8589934594|\n",
      "|Really enjoyed th...|8589934595|\n",
      "|Five Stars Amazin...|8589934596|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "corpus_df.persist()\n",
    "print('Corpus size:', corpus_df.count())\n",
    "corpus_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- id: long (nullable = false)"
     ]
    }
   ],
   "source": [
    "corpus_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Narrative text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|         review_text|               words|tokens|\n",
      "+--------------------+--------------------+------+\n",
      "|Great story! Ray ...|[great, story, ra...|    29|\n",
      "|Four Stars It's a...|[four, stars, it,...|    17|\n",
      "|Four Stars Good r...|[four, stars, goo...|     6|\n",
      "|Really enjoyed th...|[really, enjoyed,...|    29|\n",
      "|Five Stars Amazin...|[five, stars, ama...|     7|\n",
      "|Five Stars excell...|[five, stars, exc...|     4|\n",
      "|Good read The las...|[good, read, the,...|    24|\n",
      "|Five Stars Great ...|[five, stars, gre...|     8|\n",
      "|Five Stars Best h...|[five, stars, bes...|     8|\n",
      "|Loved it I read e...|[loved, it, i, re...|    17|\n",
      "|Four Stars Easy r...|[four, stars, eas...|    11|\n",
      "|wow I Should have...|[wow, i, should, ...|    23|\n",
      "|Five Stars If you...|[five, stars, if,...|    14|\n",
      "|Really Great Read...|[really, great, r...|    20|\n",
      "|Inspirational. Fo...|[inspirational, f...|    53|\n",
      "|Five Stars This i...|[five, stars, thi...|    13|\n",
      "|Good read! Very g...|[good, read, very...|     5|\n",
      "|Five Stars Awesom...|[five, stars, awe...|     4|\n",
      "|stunning ending I...|[stunning, ending...|    35|\n",
      "|Five Stars Great ...|[five, stars, gre...|     4|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"words\")\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "'''\n",
    "tokenized_df = tokenizer.transform(corpus_df)\n",
    "tokenized_df.select(\"review_text\", \"words\").withColumn(\"tokens\", countTokens(col(\"words\"))).show() \n",
    "'''\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"review_text\", \n",
    "                                outputCol=\"words\",pattern=\"\\\\w+\", gaps=False)\n",
    "# alternatively, pattern=\"\\\\w+\", gaps(False) pattern=\"\\\\W\"\n",
    "\n",
    "tokenized_df = regexTokenizer.transform(corpus_df)\n",
    "tokenized_df.select(\"review_text\", \"words\") \\\n",
    "    .withColumn(\"tokens\", countTokens(F.col(\"words\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'do', 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves', '']\n",
    "stop_words = stop_words + ['br','book','34']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+\n",
      "|         review_text|        id|               words|            filtered|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "|Great story! Ray ...|8589934592|[great, story, ra...|[great, story, ra...|\n",
      "|Four Stars It's a...|8589934593|[four, stars, it,...|[four, stars, gre...|\n",
      "|Four Stars Good r...|8589934594|[four, stars, goo...|[four, stars, goo...|\n",
      "|Really enjoyed th...|8589934595|[really, enjoyed,...|[really, enjoyed,...|\n",
      "|Five Stars Amazin...|8589934596|[five, stars, ama...|[five, stars, ama...|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|         review_text|        id|               words|            filtered|       filtered_more|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|Great story! Ray ...|8589934592|[great, story, ra...|[great, story, ra...|[great, story, ra...|\n",
      "|Four Stars It's a...|8589934593|[four, stars, it,...|[four, stars, gre...|[stars, great, ge...|\n",
      "|Four Stars Good r...|8589934594|[four, stars, goo...|[four, stars, goo...|[stars, good, rea...|\n",
      "|Really enjoyed th...|8589934595|[really, enjoyed,...|[really, enjoyed,...|[really, enjoyed,...|\n",
      "|Five Stars Amazin...|8589934596|[five, stars, ama...|[five, stars, ama...|[stars, amazing, ...|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "tokenized_df1 = remover.transform(tokenized_df)\n",
    "tokenized_df1.show(5)\n",
    "\n",
    "stopwordList = stop_words\n",
    "\n",
    "remover=StopWordsRemover(inputCol=\"filtered\", outputCol=\"filtered_more\" ,stopWords=stopwordList)\n",
    "tokenized_df2 = remover.transform(tokenized_df1)\n",
    "tokenized_df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize (convert to numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|       filtered_more|            features|        id|\n",
      "+--------------------+--------------------+----------+\n",
      "|[great, story, ra...|(10000,[1,2,6,7,2...|8589934592|\n",
      "|[stars, great, ge...|(10000,[0,2,9,32,...|8589934593|\n",
      "|[stars, good, rea...|(10000,[0,4,9,137...|8589934594|\n",
      "|[really, enjoyed,...|(10000,[7,10,11,1...|8589934595|\n",
      "|[stars, amazing, ...|(10000,[0,9,29,97...|8589934596|\n",
      "+--------------------+--------------------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Term Frequency Vectorization  - Option 2 (CountVectorizer)    : \n",
    "cv = CountVectorizer(inputCol=\"filtered_more\", outputCol=\"features\", vocabSize = 10000)\n",
    "cvmodel = cv.fit(tokenized_df2)\n",
    "featurized_df = cvmodel.transform(tokenized_df2)\n",
    "vocab = cvmodel.vocabulary\n",
    "featurized_df.select('filtered_more','features','id').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is our DF to train LDA model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in the DF: 466817"
     ]
    }
   ],
   "source": [
    "countVectors = featurized_df.select('features','id')\n",
    "countVectors.persist()\n",
    "print('Records in the DF:', countVectors.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\nll = model.logLikelihood(countVectors)\\nlp = model.logPerplexity(countVectors)\\nprint(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\\nprint(\"The upper bound on perplexity: \" + str(lp))\\n\\n# Describe topics.\\ntopics = model.describeTopics(3)\\nprint(\"The topics described by their top-weighted terms:\")\\ntopics.show(truncate=False)\\n\\n# Shows the result\\ntransformed = model.transform(countVectors)\\ntransformed.show(truncate=False)\\n'"
     ]
    }
   ],
   "source": [
    "#k=10 means 10 words per topic\n",
    "lda = LDA(k=10, maxIter=10)\n",
    "model = lda.fit(countVectors)\n",
    "\n",
    "\"\"\"\n",
    "ll = model.logLikelihood(countVectors)\n",
    "lp = model.logPerplexity(countVectors)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))\n",
    "\n",
    "# Describe topics.\n",
    "topics = model.describeTopics(3)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)\n",
    "\n",
    "# Shows the result\n",
    "transformed = model.transform(countVectors)\n",
    "transformed.show(truncate=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display words for top 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic:  0\n",
      "----------\n",
      "love\n",
      "story\n",
      "read\n",
      "loved\n",
      "like\n",
      "really\n",
      "characters\n",
      "good\n",
      "life\n",
      "m\n",
      "----------\n",
      "topic:  1\n",
      "----------\n",
      "read\n",
      "great\n",
      "story\n",
      "love\n",
      "series\n",
      "good\n",
      "books\n",
      "reading\n",
      "stars\n",
      "characters\n",
      "----------\n",
      "topic:  2\n",
      "----------\n",
      "read\n",
      "series\n",
      "like\n",
      "books\n",
      "story\n",
      "great\n",
      "mystery\n",
      "good\n",
      "author\n",
      "new\n",
      "----------\n",
      "topic:  3\n",
      "----------\n",
      "story\n",
      "read\n",
      "good\n",
      "series\n",
      "really\n",
      "like\n",
      "time\n",
      "life\n",
      "love\n",
      "little\n",
      "----------\n",
      "topic:  4\n",
      "----------\n",
      "read\n",
      "story\n",
      "great\n",
      "best\n",
      "love\n",
      "history\n",
      "books\n",
      "god\n",
      "reading\n",
      "wonderful\n",
      "----------\n",
      "topic:  5\n",
      "----------\n",
      "read\n",
      "great\n",
      "life\n",
      "amazing\n",
      "god\n",
      "time\n",
      "m\n",
      "reading\n",
      "story\n",
      "stars\n",
      "----------\n",
      "topic:  6\n",
      "----------\n",
      "read\n",
      "good\n",
      "like\n",
      "great\n",
      "life\n",
      "really\n",
      "reading\n",
      "author\n",
      "people\n",
      "time\n",
      "----------\n",
      "topic:  7\n",
      "----------\n",
      "great\n",
      "read\n",
      "recipes\n",
      "easy\n",
      "life\n",
      "like\n",
      "really\n",
      "recommend\n",
      "love\n",
      "way\n",
      "----------\n",
      "topic:  8\n",
      "----------\n",
      "stars\n",
      "good\n",
      "loved\n",
      "story\n",
      "excellent\n",
      "awesome\n",
      "y\n",
      "read\n",
      "reading\n",
      "series\n",
      "----------\n",
      "topic:  9\n",
      "----------\n",
      "read\n",
      "characters\n",
      "story\n",
      "loved\n",
      "love\n",
      "reading\n",
      "author\n",
      "series\n",
      "great\n",
      "books\n",
      "----------"
     ]
    }
   ],
   "source": [
    "topics = model.describeTopics()   \n",
    "topics_rdd = topics.rdd\n",
    "\n",
    "topics_words = topics_rdd\\\n",
    "       .map(lambda row: row['termIndices'])\\\n",
    "       .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
    "       .collect()\n",
    "\n",
    "for idx, topic in enumerate(topics_words):\n",
    "    print (\"topic: \", idx)\n",
    "    print (\"----------\")\n",
    "    for word in topic:\n",
    "       print (word)\n",
    "    print (\"----------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
